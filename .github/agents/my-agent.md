---
name:
description:
---

# My Agent

Describe what your agent does here...Describe what your agent does here...Amazon PPC Optimizer - Cloud Function Automated Amazon Advertising campaign optimization deployed on Google Cloud Functions with automatic token refresh. ðŸš€ Features Automatic Token Refresh: Tokens are automatically refreshed before API calls Serverless Deployment: Runs on Google Cloud Functions Scheduled Execution: Triggered by Cloud Scheduler Comprehensive Optimization: Bid optimization based on ACOS/performance Dayparting (time-based bid adjustments) Campaign management (auto-pause/activate) Keyword discovery and harvesting Negative keyword management Budget optimization Placement bid adjustments ðŸ“‹ Prerequisites Google Cloud Project with billing enabled Amazon Advertising API credentials: Client ID Client Secret Refresh Token Profile ID gcloud CLI installed and configured ðŸ”§ Configuration The optimizer can be configured in two ways: 1. Environment Variable (Recommended for Production) Set the PPC_CONFIG environment variable with a JSON string containing all configuration. 2. Config File (For Development) Use the config.json or sample_config.yaml files in the repository as sanitized examples only. All credentials are placeholders â€“ replace them with your own values via environment variables or Secret Manager before running in any non-local environment. Required Configuration Keys { "amazon_api": { "client_id": "amzn1.application-oa2-client.xxxxx", "client_secret": "amzn1.oa2-cs.v1.xxxxx", "refresh_token": "Atzr|IwEBIxxxxx", "profile_id": "1780498399290938", "region": "NA" }, "bid_optimization": { ... }, "dashboard": { "url": "https://ppc-dashboard.abacusai.app" } } Runtime Overrides & Secret Sources At runtime the Cloud Function inspects the following environment variables to resolve credentials and execution preferences before falling back to the bundled config.json/sample_config.yaml examples: PPC_CONFIG_PATH â€“ absolute path to a YAML/JSON configuration file mounted at runtime PPC_CONFIG â€“ JSON string containing the optimizer configuration (for Secret Manager bindings) AMAZON_PROFILE_ID / PPC_PROFILE_ID â€“ override the Amazon Ads profile ID without editing config files PPC_DRY_RUN â€“ set to true to execute without applying changes PPC_FEATURES â€“ comma separated list of feature modules to execute PPC_VERIFY_CONNECTION and PPC_VERIFY_SAMPLE_SIZE â€“ defaults for the verification helper This means you can keep sensitive values exclusively in Google Secret Manager or environment configuration; the repository examples remain sanitized. Verify Amazon Ads Connectivity After providing valid credentials, run a lightweight verification to confirm the optimizer can retrieve data from Amazon Ads (omit --profile-id if it's set in the config file): python optimizer_core.py \ --config sample_config.yaml \ --profile-id 1780498399290938 \ --verify-connection The command exits with a non-zero status if the API call fails and prints a small sample of retrieved campaigns when successful. Use --verify-sample-size=N to adjust how many campaigns are returned in the verification payload. Triggering the Optimizer via Cloud Function When deployed to Google Cloud Functions (entry point: run_optimizer), send an authenticated POST request with an optional JSON payload to run the automation: curl -X POST "https://YOUR-FUNCTION-URL" \ -H "Authorization: Bearer $FUNCTION_TOKEN" \ -H "Content-Type: application/json" \ -d '{ "profile_id": "1780498399290938", "dry_run": true, "features": ["bid_optimization", "dayparting"] }' Omit features to execute every module enabled inside the configuration file. To verify Amazon Ads connectivity through the deployed function instead of the CLI helper, call the endpoint with ?verify_connection=true and (optionally) verify_sample_size=10. The handler returns a JSON payload containing the verification sample or a descriptive error when credentials are misconfigured. ðŸš€ Deployment See DEPLOYMENT_GUIDE.md for detailed deployment instructions. Quick Deploy (Secure - Recommended) # Deploy with authentication and Secret Manager (RECOMMENDED) gcloud functions deploy amazon-ppc-optimizer \ --gen2 \ --runtime=python311 \ --region=us-central1 \ --source=. \ --entry-point=run_optimizer \ --trigger-http \ --no-allow-unauthenticated \ --timeout=540s \ --memory=512MB \ --set-secrets=AMAZON_CLIENT_ID=amazon-client-id:latest,AMAZON_CLIENT_SECRET=amazon-client-secret:latest,AMAZON_REFRESH_TOKEN=amazon-refresh-token:latest # Get the deployed function URL (Gen2 uses Cloud Run URLs) gcloud functions describe amazon-ppc-optimizer \ --region=us-central1 \ --gen2 \ --format='value(serviceConfig.uri)' Note: Gen2 Cloud Functions use Cloud Run URLs (format: https://FUNCTION_NAME-HASH-REGION.a.run.app), not the older Gen1 format (https://REGION-PROJECT.cloudfunctions.net/FUNCTION_NAME). Important Security Notes: âœ… DO use --no-allow-unauthenticated for production âœ… DO use Google Secret Manager for credentials âœ… DO configure Cloud Scheduler with proper authentication âŒ DON'T use --allow-unauthenticated (causes rate limiting issues) âŒ DON'T pass secrets as environment variables in command line ðŸ”„ Token Refresh The optimizer automatically refreshes the Amazon Advertising API access token: Before each API call, it checks if the token has expired If expired (or within 60 seconds of expiry), it automatically fetches a new token Uses the refresh_token stored in environment variables No manual intervention required The token refresh logic is built into optimizer_core.py: _authenticate(): Fetches a new access token using refresh_token _refresh_auth_if_needed(): Checks expiration and refreshes if needed Called automatically before each API request ðŸ” Security Never commit config.json with real credentials to Git Use environment variables in production The .gitignore excludes sensitive files Rotate credentials regularly ðŸ“Š Dashboard Integration The optimizer includes comprehensive dashboard integration with real-time updates: Dashboard URL: https://ppc-dashboard.abacusai.app Features Enhanced Results Payload: Detailed metrics including summary, campaigns, and top performers Real-time Progress Updates: Live status during optimization runs Error Reporting: Automatic error notification with full context Retry Logic: Exponential backoff for reliable delivery API Key Authentication: Secure communication with the dashboard Health Checks: Verify optimizer connectivity from dashboard Dashboard Triggers: Allow dashboard to trigger optimization runs Configuration Add to your config.json: { "dashboard": { "url": "https://ppc-dashboard.abacusai.app", "api_key": "your_dashboard_api_key_here", "enabled": true, "send_real_time_updates": true, "timeout": 30 } } Dashboard Endpoints The optimizer communicates with these dashboard endpoints: POST /api/optimization-results - Send completed optimization results POST /api/optimization-status - Send real-time progress updates POST /api/optimization-error - Report errors during optimization GET /api/health - Health check endpoint Triggering from Dashboard The dashboard can trigger optimization runs using: curl -X POST "https://YOUR-FUNCTION-URL?trigger=dashboard" \ -H "Authorization: Bearer YOUR_API_KEY" \ -H "Content-Type: application/json" Payload Structure The enhanced payload includes: Summary Metrics: Campaigns analyzed, keywords optimized, budget changes Feature Results: Detailed results for each optimization feature Campaign Breakdown: Per-campaign performance and changes Top Performers: Best performing keywords with metrics Errors & Warnings: Complete error context and warnings Configuration Snapshot: Settings used for this run Non-Blocking Design Dashboard communication is designed to be non-blocking: Failures don't stop optimization Automatic retries with exponential backoff Comprehensive logging of all interactions Graceful degradation if dashboard is unavailable ðŸ¥ Automated Health Check Workflow The repository includes an automated health check workflow (.github/workflows/health-check.yml) that runs after each deployment to ensure the Cloud Function is healthy and ready to use. How It Works Triggered automatically after the "Deploy to Google Cloud" workflow completes Note: If you haven't set up a deployment workflow yet, you can still manually trigger this workflow Or create a deployment workflow named "Deploy to Google Cloud" to enable automatic triggering Runs health check by calling the health endpoint: https://amazon-ppc-optimizer-nucguq3dba-uc.a.run.app/?health=true Sends email notification to natureswaysoil@gmail.com with results Posts to dashboard (optional) for visual monitoring Configure Email Notifications To enable email notifications, add these GitHub Secrets: Go to your repository: Settings â†’ Secrets and variables â†’ Actions Click New repository secret and add: Secret Name Description How to Get GMAIL_USER Your Gmail address e.g., natureswaysoil@gmail.com GMAIL_PASS Gmail App Password See below â¬‡ï¸ Getting a Gmail App Password Go to Google Account App Passwords Sign in to your Gmail account Create a new app password: App: Other (Custom name) Name: GitHub Actions Copy the 16-character password Add it as the GMAIL_PASS secret in GitHub Important: Use an App Password, NOT your regular Gmail password! App passwords are more secure and can be revoked without changing your main password. Configure Dashboard Integration , To enable dashboard API integration, add these GitHub Secrets: Secret Name Description Example DASHBOARD_API_ENDPOINT Dashboard API URL https://ppc-dashboard.abacusai.app/api/health-check DASHBOARD_API_KEY Authentication token Your dashboard API key The workflow will automatically post health check results to the dashboard if these secrets are configured. If not configured, the workflow will still complete successfully - dashboard integration is optional. Manual Testing You can manually trigger the health check workflow: Go to Actions tab in GitHub Select Health Check and Notifications workflow Click Run workflow Select the branch and click Run workflow What Gets Sent Email includes: âœ… Health check status (PASSED/FAILED) HTTP response code and body Deployment details (commit, branch, timestamp) Cloud Function URL Links to logs and dashboard Dashboard receives (if configured): Health check status and timestamp Deployment information Cloud Function endpoint details ðŸ§ª Testing Local Testing # Set environment variables export AMAZON_CLIENT_ID="your_client_id" export AMAZON_CLIENT_SECRET="your_client_secret" export AMAZON_REFRESH_TOKEN="your_refresh_token" # Run locally python main.py Dry Run (No Changes Made) # Test without making actual changes curl "https://YOUR-FUNCTION-URL?dry_run=true" ðŸ“ Project Structure . â”œâ”€â”€ main.py # Cloud Function entry point â”œâ”€â”€ optimizer_core.py # Core optimization logic with auto token refresh â”œâ”€â”€ requirements.txt # Python dependencies â”œâ”€â”€ config.json # Configuration (template, use env vars in production) â”œâ”€â”€ .gcloudignore # Files to exclude from deployment â”œâ”€â”€ .gitignore # Git ignore patterns â”œâ”€â”€ README.md # This file â””â”€â”€ DEPLOYMENT_GUIDE.md # Detailed deployment instructions ðŸ› Troubleshooting HTTP 429 (Too Many Requests) Errors If you're experiencing HTTP 429 errors: Cause: Function deployed with --allow-unauthenticated flag Unauthenticated functions have stricter rate limits Uptime checks hit the function too frequently All requests are rate-limited before function execution Solution: Redeploy with --no-allow-unauthenticated flag (see deployment section) Configure Cloud Scheduler with proper authentication (service account) Use the /health endpoint for uptime checks: ?health=true Reduce uptime check frequency or disable for this function Verify Fix: # Check logs - successful requests should show execution time > 0ms gcloud functions logs read amazon-ppc-optimizer --limit=10 Token Issues The optimizer automatically handles token refresh Check Cloud Function logs if authentication fails Verify refresh_token is valid and not expired Deployment Issues Ensure all required dependencies are in requirements.txt Check function timeout (increase if needed) Verify secrets are properly configured in Secret Manager Use --no-allow-unauthenticated for production deployments API Rate Limits The optimizer includes rate limiting (10 requests/second) Automatic retry with exponential backoff Cloud Function rate limits: use authenticated deployment to avoid issues Uptime Check Configuration To avoid triggering the main optimization logic with uptime checks: # Use health check endpoint curl "https://YOUR-FUNCTION-URL?health=true" Or configure less frequent checks (e.g., every 5-10 minutes instead of every 5-6 seconds)
