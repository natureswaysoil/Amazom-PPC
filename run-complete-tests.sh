#!/bin/bash
# Complete End-to-End Test Suite
# Run this once in Cloud Shell and walk away

set -e

PROJECT_ID="amazon-ppc-474902"
REGION="us-central1"
FUNCTION_NAME="amazon-ppc-optimizer"
FUNCTION_URL="https://amazon-ppc-optimizer-nucguq3dba-uc.a.run.app"

echo "=========================================="
echo "ðŸš€ COMPLETE PPC OPTIMIZER TEST SUITE"
echo "=========================================="
echo "Starting at: $(date)"
echo ""

# Test 1: Function Health
echo "TEST 1: Function Health Check"
echo "----------------------------------------"
TOKEN=$(gcloud auth print-identity-token)
HEALTH=$(curl -s -H "Authorization: Bearer $TOKEN" "${FUNCTION_URL}?health=true")
echo "$HEALTH" | python3 -m json.tool
echo ""

# Test 2: API Connectivity
echo "TEST 2: Amazon Ads API Verification"
echo "----------------------------------------"
curl -s -H "Authorization: Bearer $TOKEN" \
  "${FUNCTION_URL}?verify_connection=true&verify_sample_size=3" | python3 -m json.tool
echo ""

# Test 3: BigQuery Status (before optimization)
echo "TEST 3: BigQuery Data (Before)"
echo "----------------------------------------"
echo "optimization_results rows:"
bq query --use_legacy_sql=false --format=csv \
  "SELECT COUNT(*) FROM \`$PROJECT_ID.amazon_ppc.optimization_results\`" 2>/dev/null | tail -1
echo ""

# Test 4: Run Test Optimization
echo "TEST 4: Running Test Optimization (DRY RUN)"
echo "----------------------------------------"
echo "This will take 5-10 minutes for 254 campaigns..."
echo ""

RESULT=$(curl -s -X POST \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "dry_run": true,
    "features": ["bid_optimization", "dayparting", "keyword_discovery", "negative_keywords", "campaign_management"]
  }' \
  "$FUNCTION_URL")

echo "$RESULT" | python3 -m json.tool | head -100
echo ""

# Wait for data to propagate
echo "Waiting 10 seconds for data to propagate..."
sleep 10

# Test 5: BigQuery Status (after optimization)
echo "TEST 5: BigQuery Data (After)"
echo "----------------------------------------"
echo "optimization_results rows:"
bq query --use_legacy_sql=false --format=csv \
  "SELECT COUNT(*) FROM \`$PROJECT_ID.amazon_ppc.optimization_results\`" 2>/dev/null | tail -1

echo ""
echo "Last run:"
bq query --use_legacy_sql=false --format=prettyjson \
  "SELECT timestamp, run_id, status, keywords_optimized, campaigns_analyzed 
   FROM \`$PROJECT_ID.amazon_ppc.optimization_results\` 
   ORDER BY timestamp DESC LIMIT 1" 2>/dev/null | python3 -m json.tool

echo ""

# Test 6: Dashboard API
echo "TEST 6: Dashboard API Data Fetch"
echo "----------------------------------------"
curl -s "https://nextjsspace-six.vercel.app/api/bigquery-data?table=optimization_results&limit=3" | python3 -m json.tool | head -50
echo ""

# Test 7: Check Logs
echo "TEST 7: Recent Function Logs"
echo "----------------------------------------"
gcloud functions logs read $FUNCTION_NAME \
  --region=$REGION \
  --project=$PROJECT_ID \
  --limit=20 \
  --format="table(time_utc, log)" \
  2>/dev/null | tail -15

echo ""
echo "=========================================="
echo "âœ… TEST SUITE COMPLETE"
echo "=========================================="
echo "Completed at: $(date)"
echo ""
echo "ðŸ“Š Results:"
echo "  - Function: âœ… Running"
echo "  - Amazon API: âœ… Connected"
echo "  - Optimization: Check output above"
echo "  - BigQuery: Check row count above"
echo "  - Dashboard: https://nextjsspace-six.vercel.app"
echo ""
echo "ðŸ’¡ Next Steps:"
echo "  1. Review optimization results above"
echo "  2. Check dashboard for live data"
echo "  3. Run live optimization: ./run-live-optimization.sh"
echo ""
